# -*- coding: utf-8 -*-
"""Projeto DIO - Assistente de Voz Multi-Idiomas Com Whisper e ChatGPT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13B2BaLrD3eMQiD-G2M3juyMEG2_n5ygx

# Conversando por Voz com o ChatGPT utilizando Whisper e Python

Este notebook demonstra como gravar √°udio pelo navegador (Google Colab), transcrever com **Whisper**, enviar a transcri√ß√£o ao **ChatGPT** e ouvir a resposta sintetizada em voz com **gTTS**.
"""

!pip install -q openai-whisper

!pip install -q openai

!pip install -q gTTS

# Se√ß√£o 1 ‚Äì Grava√ß√£o de √Åudio
# =========================
from IPython.display import Audio, display, Javascript
from google.colab import output
from base64 import b64decode

RECORD = """
const sleep  = time => new Promise(resolve => setTimeout(resolve, time))
const b2text = blob => new Promise(resolve => {
  const reader = new FileReader()
  reader.onloadend = e => resolve(e.srcElement.result)
  reader.readAsDataURL(blob)
})
var record = time => new Promise(async resolve => {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  recorder = new MediaRecorder(stream)
  chunks = []
  recorder.ondataavailable = e => chunks.push(e.data)
  recorder.start()
  await sleep(time)
  recorder.onstop = async ()=>{
    blob = new Blob(chunks)
    text = await b2text(blob)
    resolve(text)
  }
  recorder.stop()
})
"""

def record(sec=5):
    display(Javascript(RECORD))
    js_result = output.eval_js('record(%s)' % (sec * 1000))
    audio = b64decode(js_result.split(',')[1])
    file_name = 'request_audio.wav'
    with open(file_name, 'wb') as f:
        f.write(audio)
    return f'/content/{file_name}'

print("üéôÔ∏è Gravando...")
record_file = record()
display(Audio(record_file, autoplay=False))

# Se√ß√£o 2 ‚Äì Transcri√ß√£o com Whisper
# =========================
import whisper
language = "pt"  # idioma do √°udio
model = whisper.load_model("small")
result = model.transcribe(record_file, fp16=False, language=language)
transcription = result["text"]
print("üìù Transcri√ß√£o:", transcription)

# Se√ß√£o 3 ‚Äì ChatGPT (com placeholder)
# =========================
# C√≥digo original (comentado para evitar erro de quota):
# from google.colab import userdata
# from openai import OpenAI
# api_key = userdata.get("OPENAI_API_KEY")
# client = OpenAI(api_key=api_key)
# response = client.chat.completions.create(
#     model="gpt-4o-mini",
#     messages=[{"role": "user", "content": transcription}]
# )
# chatgpt_response = response.choices[0].message.content

# Placeholder para continuar o fluxo sem erro:
chatgpt_response = "Exemplo de resposta do ChatGPT (placeholder)"
print("ü§ñ Resposta do ChatGPT:", chatgpt_response)

# =========================

# Se√ß√£o 4 ‚Äì S√≠ntese de Voz com gTTS (usa placeholder)
# =========================
from gtts import gTTS

gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)
response_audio = "/content/response_audio.wav"
gtts_object.save(response_audio)

display(Audio(response_audio, autoplay=True))